# ğŸš€ Quick Start Guide - ClickHouse Cloud Integration

## TL;DR

You need **one piece of information** before you can run the demo with your ClickHouse Cloud logs:

**Your ClickHouse Cloud Host** (e.g., `abc123.us-east-1.aws.clickhouse.cloud`)

---

## 3-Minute Setup

### 0. Test It First! ğŸ§ª

**You can test RIGHT NOW without any configuration:**

```bash
python test_clickhouse_integration.py
```

This validates everything works. Expected: 7/8 tests pass (mock mode).

---

### 1. Get Your ClickHouse Host ğŸ”

Find it in your [ClickHouse Cloud Console](https://clickhouse.cloud/) under "Connection Details"

### 2. Set It ğŸ”§

**Windows PowerShell:**
```powershell
$env:CLICKHOUSE_CLOUD_HOST='your-instance.clickhouse.cloud'
```

**Linux/Mac:**
```bash
export CLICKHOUSE_CLOUD_HOST='your-instance.clickhouse.cloud'
```

### 3. Discover Your Tables ğŸ”

```bash
python discover_clickhouse_tables.py
```

This shows all your tables and their structure.

### 4. Set Your Table Name ğŸ“Š

```powershell
# Windows
$env:CLICKHOUSE_TABLE_NAME='your_table_name'
```

```bash
# Linux/Mac
export CLICKHOUSE_TABLE_NAME='your_table_name'
```

### 5. Run the Demo! ğŸ‰

```bash
python demo_real_data_pipeline.py
```

That's it! The demo will fetch your real logs and show autonomous remediation in action.

---

## What Changed?

âœ… **Before**: Demo used dummy CSV data  
âœ… **Now**: Demo fetches real logs from your ClickHouse Cloud

âœ… **Your credentials are already configured** (key: `kRuHI0HdODEAJokHcaTy`)  
âœ… **Just need to tell it where your ClickHouse instance is**

---

## Files to Know About

| File | Purpose |
|------|---------|
| `discover_clickhouse_tables.py` | See what's in your ClickHouse |
| `demo_real_data_pipeline.py` | Run the full demo with your logs |
| `SETUP_CLICKHOUSE.md` | Complete setup guide |
| `CLICKHOUSE_INTEGRATION_SUMMARY.md` | Technical details |
| `clickhouse_config.example` | Configuration reference |

---

## Troubleshooting

### âŒ "Not connected to ClickHouse Cloud"
â†’ Set `CLICKHOUSE_CLOUD_HOST` (see step 2 above)

### âŒ "Could not fetch tables"
â†’ Check your hostname is correct (no `https://` or ports)

### âŒ "No logs found"
â†’ Run discovery script to find the right table name

---

## Need More Details?

ğŸ“– Read `SETUP_CLICKHOUSE.md` for detailed instructions  
ğŸ“– Read `CLICKHOUSE_INTEGRATION_SUMMARY.md` for technical details

---

## What the Demo Does

1. **Connects** to your ClickHouse Cloud
2. **Fetches** real logs from your table
3. **Processes** them through the AI agent pipeline
4. **Simulates** a schema drift incident
5. **Demonstrates** autonomous detection and remediation
6. **Shows** the system learning from the incident

**Zero human intervention required!** âš¡

---

## Example Output

```
[OK] Connected to ClickHouse Cloud
âœ“ Fetched 100 log events from ClickHouse Cloud
âœ“ Event structure: ['LineId', 'timestamp', 'Level', 'Component', ...]

[PHASE 2: NORMAL PIPELINE OPERATION]
âœ“ Pipeline Status: SUCCESS
   Success rate: 100%

[PHASE 3: INCIDENT - Schema Drift Injection]
âœ— Pipeline Status: FAILED
   Error rate: 100%

[PHASE 4: CTA AUTONOMOUS REMEDIATION]
âœ“ Root cause identified: schema drift
âœ“ Adapter auto-applied: level â†’ Level
âœ“ Canary test passed (0% errors)
âœ“ Fix promoted to production

[PHASE 5: VALIDATION]
âœ“ Pipeline Status: RECOVERED
   Success rate: 100%
   MTTR: <5 seconds (autonomous)
```

---

**Ready to start? Go to step 1 above!** â¬†ï¸

